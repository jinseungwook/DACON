"""
í”¼ì‹±/ìŠ¤ìº  íƒì§€ ìœ í‹¸ë¦¬í‹° - LangGraph ê¸°ë°˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
model_idea.mdì˜ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„
"""

import operator
import os
from dotenv import load_dotenv
from pathlib import Path    
from typing import Annotated, TypedDict, List, Dict, Any
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI


# 1. ìƒíƒœ ì •ì˜ (ì—ì´ì „íŠ¸ë“¤ì´ ê³µìœ í•  ë©”ëª¨ë¦¬)
class PhishingDetectionState(TypedDict):
    input_text: str
    linguistic_report: Dict[str, Any]
    security_report: Dict[str, Any]
    pattern_report: Dict[str, Any]
    final_diagnosis: Dict[str, Any]


# í”¼ì‹± íŒ¨í„´ ì •ì˜
PHISHING_PATTERNS = {
    'urgency': {
        'keywords': ['ê¸´ê¸‰', 'ì¦‰ì‹œ', '24ì‹œê°„', 'ì˜¤ëŠ˜ê¹Œì§€', 'ë§ˆê°', 'ì§€ê¸ˆ', 'ë‹¹ì¥', 'ë¹¨ë¦¬'],
        'weight': 2.5,
        'description': 'ê¸´ê¸‰ì„±ì„ ê°•ì¡°í•˜ëŠ” í‘œí˜„'
    },
    'money': {
        'keywords': ['ì†¡ê¸ˆ', 'ê³„ì¢Œ', 'ì…ê¸ˆ', 'í™˜ê¸‰', 'ì„¸ê¸ˆ', 'ê³¼íƒœë£Œ', 'ë²Œê¸ˆ', 'ë‹¹ì²¨', 'ë³´ìƒê¸ˆ', 'ìˆ˜ìˆ˜ë£Œ'],
        'weight': 3.0,
        'description': 'ê¸ˆì „ ê´€ë ¨ ìš”êµ¬'
    },
    'personal_info': {
        'keywords': ['ì£¼ë¯¼ë²ˆí˜¸', 'ë¹„ë°€ë²ˆí˜¸', 'ì¹´ë“œë²ˆí˜¸', 'ê³„ì¢Œë²ˆí˜¸', 'ì¸ì¦ë²ˆí˜¸', 'OTP', 'ë³´ì•ˆì¹´ë“œ', 'ê°œì¸ì •ë³´'],
        'weight': 3.5,
        'description': 'ê°œì¸ì •ë³´ ìš”ì²­'
    },
    'authority': {
        'keywords': ['ê²½ì°°', 'ê²€ì°°', 'ë²•ì›', 'êµ­ì„¸ì²­', 'ê¸ˆìœµê°ë…ì›', 'ì€í–‰', 'ì¹´ë“œì‚¬', 'ìš°ì²´êµ­', 'íƒë°°'],
        'weight': 2.0,
        'description': 'ê³µê³µê¸°ê´€/ê¸°ì—… ì‚¬ì¹­'
    },
    'threat': {
        'keywords': ['ë²•ì ì¡°ì¹˜', 'ê³ ì†Œ', 'ê³ ë°œ', 'ì••ë¥˜', 'ì²´í¬', 'êµ¬ì†', 'ì†Œì†¡', 'ì²˜ë²Œ', 'ì‹ ìš©ë¶ˆëŸ‰'],
        'weight': 3.0,
        'description': 'ìœ„í˜‘ì„± ë¬¸êµ¬'
    },
    'link': {
        'keywords': ['http', 'https', 'bit.ly', 'url', 'ë§í¬', 'í´ë¦­', 'ì ‘ì†'],
        'weight': 2.0,
        'description': 'ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë§í¬'
    },
    'contact': {
        'keywords': ['ì—°ë½ì£¼ì„¸ìš”', 'íšŒì‹ ', 'ë‹µì¥', 'ì „í™”', 'ë¬¸ì', 'ì¹´í†¡', 'í…”ë ˆê·¸ë¨'],
        'weight': 1.5,
        'description': 'ì—°ë½ ìš”ì²­'
    }
}

BASE_DIR = Path(__file__).resolve().parents[4]
load_dotenv(BASE_DIR / ".env")

# OpenAI API ì„¤ì •
try:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    llm = ChatOpenAI(
        model="gpt-4o-mini",  # ë˜ëŠ” "gpt-4", "gpt-3.5-turbo" ë“±
        temperature=0.3,
        api_key=api_key
    )
except Exception as e:
    print(f"Warning: OpenAI API ì´ˆê¸°í™” ì‹¤íŒ¨. íŒ¨í„´ ê¸°ë°˜ ë¶„ì„ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤: {e}")
    llm = None


# 2. ë…¸ë“œ ì •ì˜ (ê° ì—ì´ì „íŠ¸ì˜ ì—­í• )

def pattern_analyzer(state: PhishingDetectionState) -> Dict[str, Any]:
    """
    íŒ¨í„´ ë¶„ì„ ì—ì´ì „íŠ¸: í‚¤ì›Œë“œ ê¸°ë°˜ íŒ¨í„´ ë§¤ì¹­
    """
    text = state['input_text']
    
    if not text or text.strip() == '':
        return {
            'pattern_report': {
                'total_score': 0,
                'detected_patterns': [],
                'analysis': 'ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'
            }
        }
    
    normalized_text = text.lower()
    total_score = 0
    detected_patterns = []
    
    # ê° íŒ¨í„´ë³„ë¡œ í‚¤ì›Œë“œ ê²€ì‚¬
    for category, pattern in PHISHING_PATTERNS.items():
        matched_keywords = [
            keyword for keyword in pattern['keywords']
            if keyword.lower() in normalized_text
        ]
        
        if matched_keywords:
            category_score = len(matched_keywords) * pattern['weight']
            total_score += category_score
            
            detected_patterns.append({
                'category': category,
                'description': pattern['description'],
                'matched_keywords': matched_keywords,
                'score': category_score
            })
    
    return {
        'pattern_report': {
            'total_score': total_score,
            'detected_patterns': detected_patterns,
            'analysis': f'{len(detected_patterns)}ê°œì˜ ì˜ì‹¬ íŒ¨í„´ ë°œê²¬ (ì´ì : {total_score:.1f})'
        }
    }


def linguistic_expert(state: PhishingDetectionState) -> Dict[str, Any]:
    """
    ì–¸ì–´ ë¶„ì„ ì—ì´ì „íŠ¸: ì‚¬íšŒê³µí•™ì  ê¸°ë§Œ ìˆ˜ë²• ë¶„ì„
    """
    text = state['input_text']
    
    if llm is None:
        # LLMì´ ì—†ì„ ê²½ìš° íŒ¨í„´ ê¸°ë°˜ ê°„ë‹¨ ë¶„ì„
        pattern_report = state.get('pattern_report', {})
        detected = pattern_report.get('detected_patterns', [])
        
        linguistic_indicators = []
        if any(p['category'] == 'urgency' for p in detected):
            linguistic_indicators.append('ê¸´ë°•ê° ì¡°ì„±')
        if any(p['category'] == 'threat' for p in detected):
            linguistic_indicators.append('ê³µí¬ ìœ ë„')
        if any(p['category'] == 'authority' for p in detected):
            linguistic_indicators.append('ê¶Œìœ„ ì‚¬ì¹­')
        
        return {
            'linguistic_report': {
                'indicators': linguistic_indicators,
                'analysis': f'ì‚¬íšŒê³µí•™ ê¸°ë²• {len(linguistic_indicators)}ê°œ ê°ì§€',
                'confidence': 'medium'
            }
        }
    
    # LLMì„ ì‚¬ìš©í•œ ê³ ê¸‰ ë¶„ì„
    prompt = f"""ë‹¤ìŒ ë¬¸êµ¬ì˜ ì‚¬íšŒê³µí•™ì  ê¸°ë§Œ ìˆ˜ë²•ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
    
í…ìŠ¤íŠ¸: {text}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”:
1. ê¸´ë°•í•¨/ì‹œê°„ ì••ë°• ì‚¬ìš© ì—¬ë¶€
2. ê³µí¬/ë¶ˆì•ˆ ìœ ë„ ì—¬ë¶€
3. ê¶Œìœ„/ì‹ ë¢° ì‚¬ì¹­ ì—¬ë¶€
4. ë³´ìƒ/ì´ë“ ì œì‹œ ì—¬ë¶€

JSON í˜•ì‹ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""
    
    try:
        response = llm.invoke(prompt)
        return {
            'linguistic_report': {
                'analysis': response,
                'confidence': 'high'
            }
        }
    except Exception as e:
        return {
            'linguistic_report': {
                'analysis': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'confidence': 'low'
            }
        }


def security_expert(state: PhishingDetectionState) -> Dict[str, Any]:
    """
    ë³´ì•ˆ ë¶„ì„ ì—ì´ì „íŠ¸: ë§í¬, ë°œì‹  í˜•ì‹ì˜ ê¸°ìˆ ì  ìœ„í—˜ì„± ë¶„ì„
    """
    text = state['input_text']
    
    if llm is None:
        # LLMì´ ì—†ì„ ê²½ìš° íŒ¨í„´ ê¸°ë°˜ ê°„ë‹¨ ë¶„ì„
        pattern_report = state.get('pattern_report', {})
        detected = pattern_report.get('detected_patterns', [])
        
        security_risks = []
        if any(p['category'] == 'link' for p in detected):
            security_risks.append('ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë§í¬ í¬í•¨')
        if any(p['category'] == 'personal_info' for p in detected):
            security_risks.append('ê°œì¸ì •ë³´ ìš”ì²­')
        if any(p['category'] == 'money' for p in detected):
            security_risks.append('ê¸ˆì „ ê±°ë˜ ìœ ë„')
        
        return {
            'security_report': {
                'risks': security_risks,
                'analysis': f'ë³´ì•ˆ ìœ„í—˜ {len(security_risks)}ê°œ ë°œê²¬',
                'threat_level': 'high' if len(security_risks) >= 2 else 'medium' if security_risks else 'low'
            }
        }
    
    # LLMì„ ì‚¬ìš©í•œ ê³ ê¸‰ ë¶„ì„
    prompt = f"""ë‹¤ìŒ ë©”ì‹œì§€ì— í¬í•¨ëœ ë§í¬ë‚˜ ë°œì‹  í˜•ì‹ì˜ ê¸°ìˆ ì  ìœ„í—˜ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸: {text}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”:
1. URL/ë§í¬ì˜ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´
2. ê°œì¸ì •ë³´ ìš”ì²­ ì—¬ë¶€
3. ê¸ˆì „ ê±°ë˜ ìœ ë„ ì—¬ë¶€
4. ì•…ì„± í–‰ìœ„ ê°€ëŠ¥ì„±

ìœ„í—˜ë„(ë‚®ìŒ/ë³´í†µ/ë†’ìŒ/ë§¤ìš°ë†’ìŒ)ì™€ í•¨ê»˜ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""
    
    try:
        response = llm.invoke(prompt)
        return {
            'security_report': {
                'analysis': response,
                'threat_level': 'high'
            }
        }
    except Exception as e:
        return {
            'security_report': {
                'analysis': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'threat_level': 'unknown'
            }
        }


def synthesizer(state: PhishingDetectionState) -> Dict[str, Any]:
    """
    ì¢…í•© ë¶„ì„ ì—ì´ì „íŠ¸: ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… íŒë³„
    """
    pattern_report = state.get('pattern_report', {})
    linguistic_report = state.get('linguistic_report', {})
    security_report = state.get('security_report', {})
    
    total_score = pattern_report.get('total_score', 0)
    
    # ìœ„í—˜ë„ ë ˆë²¨ ê²°ì •
    if total_score >= 10:
        risk_level = 'critical'
        risk_percentage = min(100, 70 + (total_score - 10) * 2)
    elif total_score >= 6:
        risk_level = 'high'
        risk_percentage = 50 + (total_score - 6) * 5
    elif total_score >= 3:
        risk_level = 'medium'
        risk_percentage = 30 + (total_score - 3) * 6.67
    elif total_score > 0:
        risk_level = 'low'
        risk_percentage = total_score * 10
    else:
        risk_level = 'safe'
        risk_percentage = 0
    
    # ê¶Œì¥ì‚¬í•­ ìƒì„±
    recommendations = generate_recommendations(
        risk_level, 
        pattern_report.get('detected_patterns', [])
    )
    
    if llm is None:
        # LLM ì—†ì´ ê¸°ë³¸ ì¢…í•© ë¶„ì„
        final_diagnosis = {
            'risk_level': risk_level,
            'risk_score': round(risk_percentage),
            'detected_patterns': pattern_report.get('detected_patterns', []),
            'recommendations': recommendations,
            'summary': f'{risk_level.upper()} ìœ„í—˜ë„ - {len(pattern_report.get("detected_patterns", []))}ê°œ íŒ¨í„´ ê°ì§€'
        }
    else:
        # LLMì„ ì‚¬ìš©í•œ ê³ ê¸‰ ì¢…í•© ë¶„ì„
        prompt = f"""ì•„ë˜ ì„¸ ê°€ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… íŒë³„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

íŒ¨í„´ ë¶„ì„: {pattern_report.get('analysis', 'N/A')}
ì–¸ì–´ ë¶„ì„: {linguistic_report.get('analysis', 'N/A')}
ë³´ì•ˆ ë¶„ì„: {security_report.get('analysis', 'N/A')}

íŒì • ë“±ê¸‰: {risk_level} (ìœ„í—˜ë„: {round(risk_percentage)}%)
ì‚¬ìš©ìê°€ ì·¨í•´ì•¼ í•  í–‰ë™ ìš”ë ¹ì„ í¬í•¨í•˜ì—¬ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."""
        
        try:
            llm_summary = llm.invoke(prompt)
            final_diagnosis = {
                'risk_level': risk_level,
                'risk_score': round(risk_percentage),
                'detected_patterns': pattern_report.get('detected_patterns', []),
                'recommendations': recommendations,
                'summary': llm_summary,
                'detailed_analysis': {
                    'pattern': pattern_report,
                    'linguistic': linguistic_report,
                    'security': security_report
                }
            }
        except Exception as e:
            final_diagnosis = {
                'risk_level': risk_level,
                'risk_score': round(risk_percentage),
                'detected_patterns': pattern_report.get('detected_patterns', []),
                'recommendations': recommendations,
                'summary': f'{risk_level.upper()} ìœ„í—˜ë„ - ì¢…í•© ë¶„ì„ ì™„ë£Œ',
                'error': str(e)
            }
    
    return {'final_diagnosis': final_diagnosis}


def generate_recommendations(risk_level: str, patterns: List[Dict]) -> List[str]:
    """ìœ„í—˜ë„ì— ë”°ë¥¸ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    if risk_level == 'safe':
        return ['ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ í•­ìƒ ì£¼ì˜í•˜ì„¸ìš”!']
    
    # ê³µí†µ ê¶Œì¥ì‚¬í•­
    recommendations.append('âš ï¸ ë°œì‹ ìì˜ ì‹ ì›ì„ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”.')
    
    # íŒ¨í„´ë³„ ê¶Œì¥ì‚¬í•­
    has_personal_info = any(p['category'] == 'personal_info' for p in patterns)
    has_money = any(p['category'] == 'money' for p in patterns)
    has_authority = any(p['category'] == 'authority' for p in patterns)
    has_link = any(p['category'] == 'link' for p in patterns)
    
    if has_personal_info:
        recommendations.append('ğŸš« ì ˆëŒ€ ê°œì¸ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”.')
    
    if has_money:
        recommendations.append('ğŸ’° ê¸ˆì „ ìš”êµ¬ëŠ” 99% ì‚¬ê¸°ì…ë‹ˆë‹¤. ì†¡ê¸ˆí•˜ì§€ ë§ˆì„¸ìš”.')
    
    if has_authority:
        recommendations.append('ğŸ“ ê³µê³µê¸°ê´€ì€ ë¬¸ìë¡œ ê°œì¸ì •ë³´ë¥¼ ìš”êµ¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê³µì‹ ë²ˆí˜¸ë¡œ ì§ì ‘ í™•ì¸í•˜ì„¸ìš”.')
    
    if has_link:
        recommendations.append('ğŸ”— ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë§í¬ëŠ” ì ˆëŒ€ í´ë¦­í•˜ì§€ ë§ˆì„¸ìš”.')
    
    if risk_level in ['critical', 'high']:
        recommendations.append('ğŸš¨ ì¦‰ì‹œ ì‚­ì œí•˜ê³ , í•„ìš”ì‹œ ê²½ì°°ì²­ ì‚¬ì´ë²„ì•ˆì „êµ­(182)ì— ì‹ ê³ í•˜ì„¸ìš”.')
    
    return recommendations


# 3. ê·¸ë˜í”„ êµ¬ì„± (ì›Œí¬í”Œë¡œìš° ì„¤ê³„)
def create_phishing_detection_graph():
    """í”¼ì‹± íƒì§€ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
    workflow = StateGraph(PhishingDetectionState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("pattern_analyzer", pattern_analyzer)
    workflow.add_node("linguistic_expert", linguistic_expert)
    workflow.add_node("security_expert", security_expert)
    workflow.add_node("synthesizer", synthesizer)
    
    # ì›Œí¬í”Œë¡œìš° ì„¤ê³„
    workflow.set_entry_point("pattern_analyzer")
    workflow.add_edge("pattern_analyzer", "linguistic_expert")
    workflow.add_edge("linguistic_expert", "security_expert")
    workflow.add_edge("security_expert", "synthesizer")
    workflow.add_edge("synthesizer", END)
    
    return workflow.compile()


# ì „ì—­ ì•± ì¸ìŠ¤í„´ìŠ¤
phishing_detection_app = create_phishing_detection_graph()


# 4. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

def analyze_text(text: str) -> Dict[str, Any]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í”¼ì‹±/ìŠ¤ìº  ìœ„í—˜ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤
    
    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        
    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if not text or text.strip() == '':
        return {
            'risk_level': 'safe',
            'risk_score': 0,
            'detected_patterns': [],
            'recommendations': ['ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.']
        }
    
    # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = phishing_detection_app.invoke({
        'input_text': text,
        'linguistic_report': {},
        'security_report': {},
        'pattern_report': {},
        'final_diagnosis': {}
    })
    
    final_diagnosis = result.get('final_diagnosis', {})
    final_diagnosis['analyzed_text'] = text
    
    return final_diagnosis


def get_risk_color(risk_level: str) -> str:
    """ìœ„í—˜ë„ ë ˆë²¨ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜"""
    colors = {
        'safe': '#10b981',      # ì´ˆë¡ìƒ‰
        'low': '#3b82f6',       # íŒŒë€ìƒ‰
        'medium': '#f59e0b',    # ì£¼í™©ìƒ‰
        'high': '#ef4444',      # ë¹¨ê°„ìƒ‰
        'critical': '#dc2626'   # ì§„í•œ ë¹¨ê°„ìƒ‰
    }
    return colors.get(risk_level, colors['safe'])


def get_risk_label(risk_level: str) -> str:
    """ìœ„í—˜ë„ ë ˆë²¨ì— ë”°ë¥¸ í•œê¸€ ë¼ë²¨ ë°˜í™˜"""
    labels = {
        'safe': 'ì•ˆì „',
        'low': 'ë‚®ìŒ',
        'medium': 'ë³´í†µ',
        'high': 'ë†’ìŒ',
        'critical': 'ë§¤ìš° ìœ„í—˜'
    }
    return labels.get(risk_level, 'ì•Œ ìˆ˜ ì—†ìŒ')


def get_risk_emoji(risk_level: str) -> str:
    """ìœ„í—˜ë„ ë ˆë²¨ì— ë”°ë¥¸ ì´ëª¨ì§€ ë°˜í™˜"""
    emojis = {
        'safe': 'âœ…',
        'low': 'âš¡',
        'medium': 'âš ï¸',
        'high': 'ğŸš¨',
        'critical': 'ğŸ”´'
    }
    return emojis.get(risk_level, 'â“')


# 5. ë©”ì¸ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        "sdlkfjaslfjewjf;lasjfwpsdf",
        "ê¸´ê¸‰! êµ­ì„¸ì²­ì…ë‹ˆë‹¤. ì„¸ê¸ˆ í™˜ê¸‰ì„ ìœ„í•´ ê³„ì¢Œë²ˆí˜¸ë¥¼ íšŒì‹ í•´ì£¼ì„¸ìš”.",
        "ë‹¹ì²¨ë˜ì…¨ìŠµë‹ˆë‹¤! ì§€ê¸ˆ ì¦‰ì‹œ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ìƒê¸ˆì„ ìˆ˜ë ¹í•˜ì„¸ìš”."
    ]
    
    print("=== í”¼ì‹± íƒì§€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===\n")
    
    for i, text in enumerate(test_cases, 1):
        print(f"[í…ŒìŠ¤íŠ¸ {i}] {text}")
        result = analyze_text(text)
        print(f"ìœ„í—˜ë„: {get_risk_emoji(result['risk_level'])} {get_risk_label(result['risk_level'])} ({result['risk_score']}%)")
        print(f"ê¶Œì¥ì‚¬í•­: {result['recommendations'][0]}")
        print("-" * 80)
        print()
